import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Load and preprocess data
transform = transforms.Compose([transforms.ToTensor()])
train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=1000, shuffle=False)

# Define CNN
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 5 * 5, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = self.conv(x)
        return self.fc(x)

model = CNN()
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
for epoch in range(3):
    for images, labels in train_loader:
        preds = model(images)
        loss = loss_fn(preds, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1} complete")

# Evaluation
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)
print("PyTorch Test Accuracy:", correct / total)

"""
Theory Explanation:

What the program does:
This program implements a convolutional neural network (CNN) in PyTorch to classify handwritten digits from the MNIST dataset. It trains a model to recognize digits 0–9 using convolutional layers and fully connected layers.

What data structures are used and why:
- `torch.utils.data.DataLoader`: Efficiently loads data in batches, useful for training and evaluation.
- `torch.Tensor`: Represents both inputs and outputs for neural network operations.
- `nn.Sequential`: Groups layers together for cleaner architecture design.
- `nn.Module`: Provides a base class for the custom CNN model.
- `torch.no_grad()`: Prevents gradient tracking during evaluation for performance.

The key operations of the program:
1. **Data loading and transformation**:
   - Downloads MNIST and converts images to tensors.
   - Batches the data for training and testing.

2. **Model architecture**:
   - Two convolutional layers with ReLU activations and max-pooling to extract spatial features.
   - Flattened output passed through two dense layers for classification.
   - Output: logits for 10 classes (digits 0–9).

3. **Training**:
   - Forward pass: computes predictions.
   - Loss computation using cross-entropy.
   - Backward pass: gradients calculated and optimizer updates weights.

4. **Evaluation**:
   - Computes test accuracy using predictions from the model and actual labels.

Potential real-life use cases:
- Optical character recognition (OCR) in postal automation or bank cheque reading.
- Digit recognition in calculators or smart pens.
- Intelligent tutoring systems for handwritten math inputs.
- CAPTCHA solvers for digit-based verifications.

Sample input/output scenario:
- Input: 28x28 grayscale image of a handwritten "3"
- Preprocessed and passed through CNN layers
- Output: Tensor of shape [10] with scores for each digit class
  Example: `[0.01, 0.05, 0.02, 0.92, 0.01, 0.00, 0.01, 0.01, 0.02, 0.01]`
- Predicted class: 3 (highest probability score)
"""
