# Import required libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score

# Load the Iris dataset
data = pd.read_csv('iris.csv')

# View the first few rows
print(data.head())

# Assuming the target column is named 'species' or similar
X = data.iloc[:, :-1]  # All columns except the last
y = data.iloc[:, -1]   # Last column (target)

# Encode target labels if needed
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=0)

# Create and train the Na誰ve Bayes model
model = GaussianNB()
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# For multi-class confusion matrix, let's flatten it:
print("Confusion Matrix:\n", cm)

# Overall metrics
accuracy = accuracy_score(y_test, y_pred)
error_rate = 1 - accuracy
precision = precision_score(y_test, y_pred, average='macro')  # 'macro' = average over classes
recall = recall_score(y_test, y_pred, average='macro')

print(f"\nAccuracy: {accuracy:.2f}")
print(f"Error Rate: {error_rate:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

'''
Theory Explanation:

What the program does:
This program implements a Na誰ve Bayes classifier using the Iris dataset. It trains the model to classify iris flowers into different species based on their features (sepal length, sepal width, petal length, petal width), and evaluates the model using standard classification metrics.

Key operations of the program:
1. **Data Loading and Preparation**: The Iris dataset is loaded using pandas. Features and the target class (`species`) are separated. Label encoding is applied to convert species names into numeric values suitable for the model.
2. **Train-Test Split**: The dataset is split into 80% training and 20% testing using `train_test_split`, ensuring random shuffling with a fixed seed.
3. **Model Training**: A Gaussian Na誰ve Bayes classifier is created and trained on the training data. It assumes features are normally distributed and independent.
4. **Prediction and Evaluation**:
   - The trained model is used to predict classes for the test data.
   - A confusion matrix is generated to assess classification performance across the three iris species.
   - Accuracy, precision, recall, and error rate are calculated using macro averaging to handle multi-class classification.

Observations/Conclusions:
- Na誰ve Bayes is efficient and works well for classification problems, especially when the assumption of feature independence is reasonably satisfied.
- The use of macro-average precision and recall ensures that each class is treated equally, making it suitable for balanced multi-class datasets.
- The Iris dataset is a standard benchmark dataset; high accuracy indicates that the model generalizes well to unseen data.
- Confusion matrix analysis helps identify if certain species are being confused more than others, which can guide further model tuning or feature engineering.

'''
